# coding = utf-8
#!/usr/bin/python

"""

ä½œè€… ä¸¢ä¸¢å–µ ğŸš“ å†…å®¹å‡ä»äº’è”ç½‘æ”¶é›†è€Œæ¥ ä»…ä¾›äº¤æµå­¦ä¹ ä½¿ç”¨ ç‰ˆæƒå½’åŸåˆ›è€…æ‰€æœ‰ å¦‚ä¾µçŠ¯äº†æ‚¨çš„æƒç›Š è¯·é€šçŸ¥ä½œè€… å°†åŠæ—¶åˆ é™¤ä¾µæƒå†…å®¹
                    ====================Diudiumiao====================

"""

from Crypto.Util.Padding import unpad
from Crypto.Util.Padding import pad
from urllib.parse import urlencode
from urllib.parse import unquote
from Crypto.Cipher import ARC4
from urllib.parse import quote
from base.spider import Spider
from Crypto.Cipher import AES
from bs4 import BeautifulSoup
from datetime import datetime
from base64 import b64decode
import urllib.request
import urllib.parse
import datetime
import binascii
import requests
import base64
import json
import time
import sys
import re
import os

sys.path.append('..')

xurl = "https://ccc.chaojichaojichanga.com:35620"

xurl1 = "http://ccs.jshh.gzbaoxian.com"

xurl2 = "http://101.42.92.211:5560"

# æ–°å¢çš„è§£æåœ°å€
xurl3 = "https://new.tianjinzhitongdaohe.com"

headerx = {
    'User-Agent': 'Mozilla/5.0 (Linux; U; Android 8.0.0; zh-cn; Mi Note 2 Build/OPR1.170623.032) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/61.0.3163.128 Mobile Safari/537.36 XiaoMi/MiuiBrowser/10.1.1'
          }

headers = {
    "User-Agent": "com.android.chrome/131.0.6778.200 (Linux;Android 9) AndroidXMedia3/1.5.1"
          }

class Spider(Spider):
    global xurl
    global xurl1
    global xurl2
    global xurl3
    global headerx
    global headers

    def getName(self):
        return "é¦–é¡µ"

    def init(self, extend):
        pass

    def isVideoFormat(self, url):
        pass

    def manualVideoCheck(self):
        pass

    def extract_middle_text(self, text, start_str, end_str, pl, start_index1: str = '', end_index2: str = ''):
        if pl == 3:
            plx = []
            while True:
                start_index = text.find(start_str)
                if start_index == -1:
                    break
                end_index = text.find(end_str, start_index + len(start_str))
                if end_index == -1:
                    break
                middle_text = text[start_index + len(start_str):end_index]
                plx.append(middle_text)
                text = text.replace(start_str + middle_text + end_str, '')
            if len(plx) > 0:
                purl = ''
                for i in range(len(plx)):
                    matches = re.findall(start_index1, plx[i])
                    output = ""
                    for match in matches:
                        match3 = re.search(r'(?:^|[^0-9])(\d+)(?:[^0-9]|$)', match[1])
                        if match3:
                            number = match3.group(1)
                        else:
                            number = 0
                        if 'http' not in match[0]:
                            output += f"#{match[1]}${number}{xurl}{match[0]}"
                        else:
                            output += f"#{match[1]}${number}{match[0]}"
                    output = output[1:]
                    purl = purl + output + "$$$"
                purl = purl[:-3]
                return purl
            else:
                return ""
        else:
            start_index = text.find(start_str)
            if start_index == -1:
                return ""
            end_index = text.find(end_str, start_index + len(start_str))
            if end_index == -1:
                return ""

        if pl == 0:
            middle_text = text[start_index + len(start_str):end_index]
            return middle_text.replace("\\", "")

        if pl == 1:
            middle_text = text[start_index + len(start_str):end_index]
            matches = re.findall(start_index1, middle_text)
            if matches:
                jg = ' '.join(matches)
                return jg

        if pl == 2:
            middle_text = text[start_index + len(start_str):end_index]
            matches = re.findall(start_index1, middle_text)
            if matches:
                new_list = [f'{item}' for item in matches]
                jg = '$$$'.join(new_list)
                return jg

    def homeContent(self, filter):
        result = {}
        result = {"class": [{"type_id": "éƒ½å¸‚@%E9%", "type_name": "éƒ½å¸‚"},
                            {"type_id": "åè½¬@%E5%", "type_name": "åè½¬"},
                            {"type_id": "èŒå®@%E8%", "type_name": "èŒå®"},
                            {"type_id": "å¤è£…@%E5%", "type_name": "å¤è£…"},
                            {"type_id": "é€†è¢­@%E9%", "type_name": "é€†è¢­"},
                            {"type_id": "å–œå‰§@%E5%", "type_name": "å–œå‰§"},
                            {"type_id": "é—ªå©š@%E9%", "type_name": "é—ªå©š"},
                            {"type_id": "ç‹å¦ƒ@%E7%", "type_name": "ç‹å¦ƒ"},
                            {"type_id": "æ ¡å›­@%E6%", "type_name": "æ ¡å›­"},
                            {"type_id": "æ°‘å›½@%E6%", "type_name": "æ°‘å›½"},
                            {"type_id": "å¹´ä»£@%E5%", "type_name": "å¹´ä»£"},
                            {"type_id": "è„‘æ´@%E8%", "type_name": "è„‘æ´"},
                            {"type_id": "æ€»è£@%E6%", "type_name": "æ€»è£"}],
                 }

        return result

    def decrypt1(self, encrypted_base64_content, key_text):
        key_text = key_text
        key = key_text.encode('utf-8')
        encrypted_bytes = base64.b64decode(encrypted_base64_content)
        cipher = AES.new(key, AES.MODE_ECB)
        decrypted_padded_bytes = cipher.decrypt(encrypted_bytes)
        decrypted_bytes = unpad(decrypted_padded_bytes, AES.block_size)
        decrypted_text = decrypted_bytes.decode('utf-8')
        parsed_json = json.loads(decrypted_text)
        return parsed_json

    def process_video_data(self, detail):
        videos = []
        js = detail['data']
        for vod in js:
            name = vod['vod_name']
            id = vod['vod_id']
            pic = vod['vod_pic']
            remark = vod['vod_douban_score']
            video = {
                "vod_id": id,
                "vod_name": name,
                "vod_pic": pic,
                "vod_remarks": 'ï¸è±†ç“£è¯„åˆ†' + remark + 'åˆ†'
                    }
            videos.append(video)
        return videos

    def homeVideoContent(self):
        videos = []

        for page in [1, 2, 3]:

            params = {
                "class": "",
                "order": "æœ€æ–°",
                "type_id": 5,
                "area": "",
                "year": "",
                "state": "",
                "wd": "",
                "page": page
                     }

            url = f"{xurl}/list"
            detail = requests.get(url=url, params=params, headers=headerx)
            detail.encoding = "utf-8"
            res = detail.text

            key_text = f"/list?class=&ord"
            detail = self.decrypt1(res, key_text)
            videos = self.process_video_data(detail)

        result = {'list': videos}
        return result

    def categoryContent(self, cid, pg, filter, ext):
        result = {}
        videos = []

        fenge = cid.split("@")

        if pg:
            page = int(pg)
        else:
            page = 1

        params = {
            "class": fenge[0],
            "order": "æœ€æ–°",
            "type_id": 5,
            "area": "",
            "year": "",
            "state": "",
            "wd": "",
            "page": str(page)
                 }

        url = f"{xurl}/list"
        detail = requests.get(url=url, params=params, headers=headerx)
        detail.encoding = "utf-8"
        res = detail.text

        key_text = f"/list?class={fenge[1]}"
        detail = self.decrypt1(res , key_text)
        videos = self.process_video_data(detail)

        result = {'list': videos}
        result['page'] = pg
        result['pagecount'] = 9999
        result['limit'] = 90
        result['total'] = 999999
        return result

    def detailContent(self, ids):
        did = ids[0]
        result = {}
        videos = []
        xianlu = ''
        bofang = ''

        url = f"{xurl}/detail?vod_id={did}"
        detail = requests.get(url=url, headers=headerx)
        detail.encoding = "utf-8"
        res = detail.text

        vod_id = str(did)[0]
        key_text = f"/detail?vod_id={vod_id}"
        detail = self.decrypt1(res, key_text)

        content = detail['data']['vod_content']

        remarks = "å…±" + str(detail['data']['vod_total']) + "é›†"

        year = detail['data']['vod_year']

        area = detail['data']['vod_area']

        soup = detail['data']['sources'][0]['episodes']

        for sou in soup:

            id = sou['url']

            name = sou['name']

            bofang = bofang + name + '$' + id + '#'

        bofang = bofang[:-1]

        xianlu = 'ç‰›ç‰›çŸ­å‰§'

        videos.append({
            "vod_id": did,
            "vod_remarks": remarks,
            "vod_year": year,
            "vod_area": area,
            "vod_content": content,
            "vod_play_from": xianlu,
            "vod_play_url": bofang
                     })

        result['list'] = videos
        return result

    def playerContent(self, flag, id, vipFlags):
        # å®šä¹‰è§£ææ¥å£åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        parse_urls = [
            # ç¬¬ä¸€ä¸ªæ¥å£
            f"{xurl1}/jx/qy.php?url={id}",
            f"{xurl1}/jx/dj.php?url={id}",
            # ç¬¬äºŒä¸ªæ¥å£
            f"{xurl2}/jx/dj.php?url={id}",
            # æ–°å¢çš„ç¬¬ä¸‰ä¸ªæ¥å£
            f"{xurl3}/jx/qy.php?url={id}",
            f"{xurl3}/jx/dj.php?url={id}",
            # å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
            f"{xurl3}/player/api.php?url={id}",
            f"{xurl3}/play/api.php?url={id}",
            f"{xurl3}/parse/index.php?url={id}"
        ]
        
        url = None
        last_error = ""
        
        # å°è¯•æ‰€æœ‰è§£ææ¥å£
        for parse_url in parse_urls:
            try:
                print(f"DEBUG: Trying parse_url: {parse_url}")
                # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…
                detail = requests.get(url=parse_url, headers=headerx, timeout=15, verify=False)
                detail.encoding = "utf-8"
                res = detail.text
                
                # æ£€æŸ¥è¿”å›å†…å®¹æ˜¯å¦ä¸ºç©º
                if not res or res.strip() == "":
                    print(f"DEBUG: Empty response from {parse_url}")
                    last_error = f"Empty response from {parse_url}"
                    continue
                
                # å°è¯•è§£æ JSON
                try:
                    data = json.loads(res)
                    print(f"DEBUG: JSON parsed successfully from {parse_url}")
                    
                    if "url" in data and data["url"] and data["url"].strip() != "":
                        url = data["url"]
                        print(f"DEBUG: Found url from JSON: {url}")
                        break
                    elif "m3u8" in data and data["m3u8"] and data["m3u8"].strip() != "":
                        url = data["m3u8"]
                        print(f"DEBUG: Found m3u8 from JSON: {url}")
                        break
                    elif "video" in data and data["video"] and data["video"].strip() != "":
                        url = data["video"]
                        print(f"DEBUG: Found video from JSON: {url}")
                        break
                    else:
                        print(f"DEBUG: No valid url in JSON response from {parse_url}")
                        last_error = f"No valid url in JSON response from {parse_url}"
                        
                except json.JSONDecodeError:
                    # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ä»HTMLä¸­æå–è§†é¢‘åœ°å€
                    print(f"DEBUG: Not JSON format from {parse_url}, trying to extract from HTML")
                    
                    # å°è¯•ä»HTMLä¸­æå–m3u8æˆ–mp4åœ°å€
                    patterns = [
                        r'"(https?://[^"\']+\.m3u8[^"\']*)"',
                        r'"(https?://[^"\']+\.mp4[^"\']*)"',
                        r'src="(https?://[^"\']+\.m3u8[^"\']*)"',
                        r'src="(https?://[^"\']+\.mp4[^"\']*)"',
                        r'url\s*:\s*"(https?://[^"\']+)"',
                        r'video\s*:\s*"(https?://[^"\']+)"'
                    ]
                    
                    for pattern in patterns:
                        matches = re.findall(pattern, res, re.IGNORECASE)
                        if matches:
                            url = matches[0]
                            print(f"DEBUG: Found video URL from HTML with pattern {pattern}: {url}")
                            break
                    
                    if url:
                        break
                        
            except requests.RequestException as e:
                print(f"DEBUG: Request error for {parse_url}: {e}")
                last_error = f"Request error: {e}"
                continue
            except Exception as e:
                print(f"DEBUG: Unexpected error for {parse_url}: {e}")
                last_error = f"Unexpected error: {e}"
                continue
        
        # å¦‚æœæ‰€æœ‰è§£ææ¥å£éƒ½å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        if not url:
            print(f"DEBUG: All parse URLs failed, trying alternative methods")
            
            # æ–¹æ³•1: å°è¯•ç›´æ¥ä½¿ç”¨idä½œä¸ºæ’­æ”¾åœ°å€ï¼ˆå¦‚æœæ˜¯å®Œæ•´URLï¼‰
            if id.startswith(('http://', 'https://', '//')):
                url = id
                print(f"DEBUG: Using id as direct URL: {url}")
            
            # æ–¹æ³•2: å°è¯•base64è§£ç 
            elif id and len(id) > 10:
                try:
                    # å°è¯•ç›´æ¥base64è§£ç 
                    decoded = base64.b64decode(id).decode('utf-8')
                    if decoded.startswith(('http://', 'https://', '//')):
                        url = decoded
                        print(f"DEBUG: Using base64 decoded URL: {url}")
                except:
                    # å¦‚æœä¸æ˜¯æ ‡å‡†base64ï¼Œå°è¯•æ·»åŠ paddingåè§£ç 
                    try:
                        padding = 4 - len(id) % 4
                        if padding != 4:
                            id_padded = id + '=' * padding
                            decoded = base64.b64decode(id_padded).decode('utf-8')
                            if decoded.startswith(('http://', 'https://', '//')):
                                url = decoded
                                print(f"DEBUG: Using padded base64 decoded URL: {url}")
                    except:
                        pass
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°URLï¼Œå°è¯•ä»å›ºå®šçš„å¤‡ç”¨åœ°å€æ„å»º
        if not url and id:
            print(f"DEBUG: Still no URL found, trying backup methods")
            
            # æ£€æŸ¥idæ˜¯å¦æ˜¯ç›¸å¯¹è·¯å¾„
            if not id.startswith(('http://', 'https://', '//', 'magnet:', 'ftp:')):
                # å°è¯•ç»„åˆæˆå®Œæ•´URL
                backup_hosts = [
                    xurl,
                    xurl1,
                    xurl2,
                    xurl3,
                    "https://vip.ffzy-online6.com",
                    "https://vip.ffzy-online5.com"
                ]
                
                for host in backup_hosts:
                    test_url = f"{host}/{id.lstrip('/')}"
                    # ç®€å•æµ‹è¯•è¯¥URLæ˜¯å¦æœ‰æ•ˆ
                    try:
                        test_resp = requests.head(test_url, timeout=5, allow_redirects=True)
                        if test_resp.status_code < 400:
                            url = test_url
                            print(f"DEBUG: Found working backup URL: {url}")
                            break
                    except:
                        continue
        
        # æ„å»ºç»“æœ
        result = {}
        result["parse"] = 0
        result["playUrl"] = ''
        result["header"] = headerx
        
        if url:
            result["url"] = url
            print(f"DEBUG: Success! Final URL: {url}")
        else:
            result["url"] = ''
            print(f"DEBUG: Failed to get play URL. Last error: {last_error}")
            print(f"DEBUG: Original id was: {id}")
            
            # ä½œä¸ºæœ€åçš„æ‰‹æ®µï¼Œè¿”å›ä¸€ä¸ªæµ‹è¯•ç”¨çš„æ’­æ”¾åœ°å€ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            # è¿™è¡Œä»£ç å¯ä»¥æ³¨é‡Šæ‰ï¼Œä»…ä¾›æµ‹è¯•ä½¿ç”¨
            # result["url"] = "https://example.com/test.mp4"
        
        return result

    def searchContentPage(self, key, quick, pg):
        result = {}
        videos = []

        if pg:
            page = int(pg)
        else:
            page = 1

        params = {
            "class": "",
            "order": "",
            "type_id": 5,
            "area": "",
            "year": "",
            "state": "",
            "wd": key,
            "page": str(page)
                 }

        url = f"{xurl}/list"
        detail = requests.get(url=url, params=params, headers=headerx)
        detail.encoding = "utf-8"
        res = detail.text

        key_text = f"/list?class=&ord"
        detail = self.decrypt1(res, key_text)
        videos = self.process_video_data(detail)

        result = {'list': videos}
        result['page'] = page
        result['pagecount'] = 9999
        result['limit'] = 90
        result['total'] = 999999
        return result

    def searchContent(self, key, quick, pg="1"):
        return self.searchContentPage(key, quick, '1')

    def localProxy(self, params):
        if params['type'] == "m3u8":
            return self.proxyM3u8(params)
        elif params['type'] == "media":
            return self.proxyMedia(params)
        elif params['type'] == "ts":
            return self.proxyTs(params)
        return None